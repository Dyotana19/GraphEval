
import subprocess
import os
import pandas as pd


# prompt the user to enter the path to their bash script and an argument
#bash_script_path = input("Enter the path to your bash script: ")
arg3 = input("Enter the toolname used to build the graph : ")
arg1 = input("Enter graph (in .gfa/.fasta format): ")
arg2 = input("Enter read (.fq/.fastq/.fasta file): ")
arg4 = input("Mention number of threads : ")

# run the bash script using subprocess
process = subprocess.Popen(['bash', "align.sh", arg1, arg2,arg3,arg4], stdout=subprocess.PIPE)
output, error = process.communicate()

# print any output or error messages generated by the bash script
if output:
    print(output.decode("utf-8"))
if error:
    print(error.decode("utf-8"))

#read the output file and print the statistics
folder_name = arg3 + "_result"
folder_path = 'output/' + folder_name

#folder_path = '/global/homes/d/dyotana/GraphEval/output/' + folder_name
#print(folder_name)


# create an empty list to store the data frames
dfs = []

# loop over all the subdirectories of xyz
for subdir in os.listdir(folder_path):
    # check if the subdirectory contains TSV files
    subdir_path = os.path.join(folder_path, subdir)
    if os.path.isdir(subdir_path) and any(fname.endswith('.tsv') for fname in os.listdir(subdir_path)):
        # loop over all the TSV files in the subdirectory and append the resulting data frames to the list
        for file in os.listdir(subdir_path):
            if file.endswith('.tsv'):
                file_path = os.path.join(subdir_path, file)
                df = pd.read_csv(file_path, sep='\t')
                dfs.append(df)

# concatenate the data frames in the list into a single data frame
merged_df = pd.concat(dfs)

# write the merged data frame to a new TSV file
merged_df.to_csv('Merge_' + arg3 +'.tsv', sep='\t', index=False)


# calculate the percentage of zeros in the 'cost' column : perfectly aligned reads
zero_percent = (merged_df['cost'] == 0).mean() * 100
print(f"Percentage of perfectly aligned reads : {zero_percent:.2f}%")


#read the stat log to find out the time and memory requirement

stat_dfs = []

# loop over all the subdirectories of xyz
for subdir in os.listdir(folder_path):
    # check if the subdirectory contains TSV files
    subdir_path = os.path.join(folder_path, subdir)
    if os.path.isdir(subdir_path) and any(fname.endswith('.log') for fname in os.listdir(subdir_path)):
        # loop over all the TSV files in the subdirectory and append the resulting data frames to the list
        for file in os.listdir(subdir_path):
            if file.endswith('.log'):
                file_path = os.path.join(subdir_path, file)
                df = pd.read_csv(file_path, sep='\t')
                stat_dfs.append(df)

# concatenate the data frames in the list into a single data frame
merged_log = pd.concat(stat_dfs)

# write the merged data frame to a new TSV file
merged_log.to_csv('Merge_' + arg3 +'.log', sep='\t', index=False)

#print the total time and totl memory requirement 
sum_memory = merged_log['total_gb'].sum()
sum_time = merged_log['total_sec'].sum()

print(f"Total memory (in gb) : {sum_memory:.2f}")
print(f"Total time (in sec) : {sum_time:.2f}")
